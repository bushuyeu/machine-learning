{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tjcZhRfr6GTU","executionInfo":{"status":"ok","timestamp":1768515427815,"user_tz":600,"elapsed":8741,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1fb341a0-24ed-42de-9bbc-d72869f1dae3"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'svd_directions' already exists and is not an empty directory.\n","/content/svd_directions\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.57.3)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.0.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.13.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.10.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (3.20.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (0.22.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 1)) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 2)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 2)) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 2)) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 2)) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 2)) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (2025.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.3.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.9.0.post0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (3.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 1)) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 1)) (1.2.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2025.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2026.1.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (1.22.0)\n","Cloning into 'PySvelte'...\n","remote: Enumerating objects: 148, done.\u001b[K\n","remote: Counting objects: 100% (22/22), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 148 (delta 15), reused 13 (delta 13), pack-reused 126 (from 1)\u001b[K\n","Receiving objects: 100% (148/148), 1.85 MiB | 7.28 MiB/s, done.\n","Resolving deltas: 100% (72/72), done.\n","Obtaining file:///content/svd_directions/PySvelte\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pysvelte==1.0.1) (2.9.0+cu126)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from pysvelte==1.0.1) (0.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pysvelte==1.0.1) (2.0.2)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.12/dist-packages (from pysvelte==1.0.1) (4.4.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->pysvelte==1.0.1) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pysvelte==1.0.1) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pysvelte==1.0.1) (3.0.3)\n","Installing collected packages: pysvelte\n","  Running setup.py develop for pysvelte\n","Successfully installed pysvelte-1.0.1\n"]}],"source":["\n","\n","# install repo with the data\n","!git clone https://github.com/BerenMillidge/svd_directions\n","%cd svd_directions\n","\n","!bash setup.sh\n","\n","import torch\n","from collections import Counter\n","import termcolor\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc\n","from copy import deepcopy\n","from tqdm.auto import tqdm, trange\n","import re\n","from collections import defaultdict\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","# utils\n","import json\n","from torch import nn\n","import torch.nn.functional as F\n","from datasets import load_dataset\n","from copy import deepcopy\n","from torch.nn import functional as F\n","from tabulate import tabulate\n","from tqdm import tqdm, trange\n","import functools\n","import math"]},{"cell_type":"code","source":["torch.cuda.is_available()\n","!nvidia-smi\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-14fXo5tfQq","executionInfo":{"status":"ok","timestamp":1768515445445,"user_tz":600,"elapsed":124,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"bd065b97-374c-4ba9-d360-baec54f26339"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jan 15 22:17:25 2026       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P0             30W /   70W |    1560MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmBu6Kmi6GTW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768515462569,"user_tz":600,"elapsed":2419,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"18a43c3b-41ea-429b-a466-1060f95d5fc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"dtype\": \"float32\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 1024,\n","  \"n_special\": 0,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.57.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}],"source":["model = AutoModelForCausalLM.from_pretrained(\n","    \"gpt2-medium\"\n",").to('cuda')\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n","print(model.config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tct2KJif6GTX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764008634864,"user_tz":600,"elapsed":51,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"281a229c-5c0d-4e03-fe91-9f7cf1417561"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  523, 28766,   321, 28730,  2521, 28766, 28767,  1838,    13,  6802,\n","           349,   264, 28475, 28804, 28789, 28766,   321, 28730,   416, 28766,\n","         28767,    13]])\n","<|im_start|>user\n","what is a GPU?<|im_end|>\n","\n","torch.Size([1, 22])\n"]}],"source":["messages=  [\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"what is a GPU?\",\n","        },\n","    ]\n","\n","encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","\n","print(encodeds)\n","print(tokenizer.decode(encodeds[0]))\n","print(encodeds.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFvBPczG6GTX"},"outputs":[],"source":["model_inputs = encodeds.to(\"cuda\")\n","with torch.no_grad():\n","        logits =  model(model_inputs).logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvLG8XQg6GTX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760954365247,"user_tz":600,"elapsed":27,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"e772fae7-156e-4b1a-8da9-0b6b75e12af1"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 22, 50257])\n"]}],"source":["print(logits.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6mRb5VSU6GTY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760954513279,"user_tz":600,"elapsed":30,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"0253f50e-a4c7-4eac-eb8f-711985b4cda5"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50257, 1024])\n"]}],"source":["for param in model.named_parameters():\n","    if 'wte' in param[0]:\n","      WE = param[1]\n","\n","print(WE.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5OVtyFP6GTY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760954519219,"user_tz":600,"elapsed":62,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"07daa63c-260a-4051-866d-1960e9de6441"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[653.3  60.4 126.9 231.8  81.6]\n"," [ 60.4 474.9  35.4  61.4  14.4]\n"," [126.9  35.4 547.2 191.2  75.6]\n"," [231.8  61.4 191.2 900.6 109.8]\n"," [ 81.6  14.4  75.6 109.8 527.4]]\n"]}],"source":["import numpy as np\n","\n","prod = WE.T @ WE\n","print(np.round(prod[:5,:5].detach().cpu().numpy(),1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgM8_M6K6GTY"},"outputs":[],"source":["for param in model.named_parameters():\n","    print(param[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhkXCmM66GTY"},"outputs":[],"source":["for param in model.named_parameters():\n","    if 'layers.0' in param[0]:\n","        print(param[0],'\\n')\n","        print('Shape: ', param[1].shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kT874eBq6GTZ"},"outputs":[],"source":["import site\n","site.main()\n","\n","sns.set_palette('colorblind')\n","cmap = sns.color_palette('colorblind')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nc0evW5p6GTZ"},"outputs":[],"source":["def keep_k(x, k=100, absolute=True, dim=-1):\n","    shape = x.shape\n","    x_ = x\n","    if absolute:\n","        x_ = abs(x)\n","    values, indices = torch.topk(x_, k=k, dim=dim)\n","    res = torch.zeros_like(x)\n","    res.scatter_(dim, indices, x.gather(dim, indices))\n","    return res\n","\n","def get_max_token_length(tokens):\n","  maxlen = 0\n","  for t in tokens:\n","    l = len(t)\n","    if l > maxlen:\n","      maxlen = l\n","  return maxlen\n","\n","def pad_with_space(t, maxlen):\n","  spaces_to_add = maxlen - len(t)\n","  for i in range(spaces_to_add):\n","    t += \" \"\n","  return t\n","\n","def convert_to_tokens(indices, tokenizer, extended, extra_values_pos, strip=True, pad_to_maxlen=False):\n","    if extended:\n","        res = [tokenizer.convert_ids_to_tokens([idx])[0] if idx < len(tokenizer) else\n","               (f\"[pos{idx-len(tokenizer)}]\" if idx < extra_values_pos else f\"[val{idx-extra_values_pos}]\")\n","               for idx in indices]\n","    else:\n","        res = tokenizer.convert_ids_to_tokens(indices)\n","    if strip:\n","        res = list(map(lambda x: x[1:] if x[0] == 'Ġ' else \"#\" + x, res))\n","    if pad_to_maxlen:\n","      maxlen = get_max_token_length(res)\n","      res = list(map(lambda t: pad_with_space(t, maxlen), res))\n","    return res\n","\n","\n","def top_tokens(v_tok, k=100, tokenizer=None, only_english=False, only_ascii=True, with_values=False,\n","               exclude_brackets=False, extended=True, extra_values=None, pad_to_maxlen=False):\n","    if tokenizer is None:\n","        tokenizer = my_tokenizer\n","    v_tok = deepcopy(v_tok)\n","    ignored_indices = []\n","    if only_ascii:\n","        ignored_indices = [key for val, key in tokenizer.vocab.items() if not val.strip('Ġ').isascii()]\n","    if only_english:\n","        ignored_indices =[key for val, key in tokenizer.vocab.items() if not (val.strip('Ġ').isascii() and val.strip('Ġ[]').isalnum())]\n","    if exclude_brackets:\n","        ignored_indices = set(ignored_indices).intersection(\n","            {key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.isalnum())})\n","        ignored_indices = list(ignored_indices)\n","    v_tok[ignored_indices] = -np.inf\n","    extra_values_pos = len(v_tok)\n","    if extra_values is not None:\n","        v_tok = torch.cat([v_tok, extra_values])\n","    values, indices = torch.topk(v_tok, k=k)\n","    res = convert_to_tokens(indices, tokenizer, extended=extended, extra_values_pos=extra_values_pos,pad_to_maxlen = pad_to_maxlen)\n","    if with_values:\n","        res = list(zip(res, values.cpu().numpy()))\n","    return res\n","\n","\n","def top_matrix_tokens(mat, k=100, tokenizer=None, rel_thresh=None, thresh=None,\n","                      sample_entries=10000, alphabetical=True, only_english=False,\n","                      exclude_brackets=False, with_values=True, extended=True):\n","    if tokenizer is None:\n","        tokenizer = my_tokenizer\n","    mat = deepcopy(mat)\n","    ignored_indices = []\n","    if only_english:\n","        ignored_indices = [key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.strip('[]').isalnum())]\n","    if exclude_brackets:\n","        ignored_indices = set(ignored_indices).intersection(\n","            {key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.isalnum())})\n","        ignored_indices = list(ignored_indices)\n","    mat[ignored_indices, :] = -np.inf\n","    mat[:, ignored_indices] = -np.inf\n","    cond = torch.ones_like(mat).bool()\n","    if rel_thresh:\n","        cond &= (mat > torch.max(mat) * rel_thresh)\n","    if thresh:\n","        cond &= (mat > thresh)\n","    entries = torch.nonzero(cond)\n","    if sample_entries:\n","        entries = entries[np.random.randint(len(torch.nonzero(cond)), size=sample_entries)]\n","    res_indices = sorted(entries,\n","                         key=lambda x: x[0] if alphabetical else -mat[x[0], x[1]])\n","    res = [*map(partial(convert_to_tokens, extended=extended, tokenizer=tokenizer), res_indices)]\n","\n","    if with_values:\n","        res_ = []\n","        for (x1, x2), (i1, i2) in zip(res, res_indices):\n","            res_.append((x1, x2, mat[i1][i2].item()))\n","        res = res_\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGi5rDmo6GTZ"},"outputs":[],"source":["def rgetattr(obj, attr, *args):\n","    def _getattr(obj, attr):\n","        return getattr(obj, attr, *args)\n","    return functools.reduce(_getattr, [obj] + attr.split('.'))\n","\n","def rsetattr(obj, attr, val):\n","    pre, _, post = attr.rpartition('.')\n","    return setattr(rgetattr(obj, pre) if pre else obj, post, val)\n","\n","def get_model_tokenizer_embedding(model_name=\"gpt2-medium\"):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  if device == 'cpu':\n","    print(\"WARNING: you should probably restart on a GPU runtime\")\n","\n","  model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","  emb = model.get_output_embeddings().weight.data.T.detach()\n","  return model, tokenizer, emb, device\n","\n","\n","def get_model_info(model):\n","  num_layers = model.config.n_layer\n","  num_heads = model.config.n_head\n","  hidden_dim = model.config.n_embd\n","  head_size = hidden_dim // num_heads\n","  return num_layers, num_heads, hidden_dim, head_size\n","\n","def get_mlp_weights(model,num_layers, hidden_dim):\n","  Ks = []\n","  Vs = []\n","  for j in range(num_layers):\n","    K = model.get_parameter(f\"transformer.h.{j}.mlp.c_fc.weight\").T.detach()\n","    # fuse the layernorm\n","    ln_2_weight = model.get_parameter(f\"transformer.h.{j}.ln_2.weight\").detach()\n","    K = torch.einsum(\"oi,i -> oi\", K, ln_2_weight)\n","\n","    V = model.get_parameter(f\"transformer.h.{j}.mlp.c_proj.weight\")\n","    Ks.append(K)\n","    Vs.append(V)\n","\n","  Ks =  torch.cat(Ks)\n","  Vs = torch.cat(Vs)\n","  K_heads = Ks.reshape(num_layers, -1, hidden_dim)\n","  V_heads = Vs.reshape(num_layers, -1, hidden_dim)\n","  return K_heads, V_heads\n","\n","\n","def top_singular_vectors(mat, emb, all_tokens, k = 20, N_singular_vectors = 10, with_negative = False,use_visualization=False, filter=\"topk\"):\n","  U,S,V = torch.linalg.svd(mat)\n","  Vs = []\n","  for i in range(N_singular_vectors):\n","      acts = V[i,:].float() @ emb\n","      Vs.append(acts)\n","  if use_visualization:\n","    Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","    pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","  else:\n","    Vs = [top_tokens(Vs[i].float().cpu(), k = k, pad_to_maxlen=True) for i in range(len(Vs))]\n","    print(tabulate([*zip(*Vs)]))\n","  if with_negative:\n","    Vs = []\n","    for i in range(N_singular_vectors):\n","      acts = -V[i,:].float() @ emb\n","      Vs.append(acts)\n","    if use_visualization:\n","      Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","      pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","    else:\n","      Vs = [top_tokens(Vs[i].float().cpu(), k = k, pad_to_maxlen=True) for i in range(len(Vs))]\n","      print(tabulate([*zip(*Vs)]))\n","\n","def plot_MLP_singular_vectors(K,layer_idx, max_rank=None):\n","  W_matrix = K[layer_idx, :,:]\n","  U,S,V = torch.linalg.svd(W_matrix,full_matrices=False)\n","  if not max_rank:\n","    max_rank = len(S)\n","  if max_rank > len(S):\n","    max_rank = len(S) -1\n","  plt.plot(S[0:max_rank].detach().cpu().numpy())\n","  plt.yscale('log')\n","  plt.ylabel(\"Singular value\")\n","  plt.xlabel(\"Rank\")\n","  plt.title(\"Distribution of the singular vectors\")\n","  plt.show()\n","\n","def cosine_sim(x,y):\n","    return torch.dot(x,y) / (torch.norm(x) * torch.norm(y))\n","\n","\n","def normalize_and_entropy(V, eps=1e-6):\n","    absV = torch.abs(V)\n","    normV = absV / torch.sum(absV)\n","    entropy = torch.sum(normV * torch.log(normV + eps)).item()\n","    return -entropy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtnPVnG66GTa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768515527184,"user_tz":600,"elapsed":2707,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"de2ad63c-ad88-4a19-fc6c-3842871cd342"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"dtype\": \"float32\",\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 1024,\n","  \"n_special\": 0,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.57.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}],"source":["model, tokenizer, emb, device = get_model_tokenizer_embedding()\n","my_tokenizer = tokenizer\n","num_layers, num_heads, hidden_dim, head_size = get_model_info(model)\n","all_tokens = [tokenizer.decode([i]) for i in range(tokenizer.vocab_size)]\n","\n","print(model.config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2mBD0aF6GTa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760955014077,"user_tz":600,"elapsed":31,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"fa3ff535-e3e5-4e92-c50f-3c6815e729da"},"outputs":[{"output_type":"stream","name":"stdout","text":["I \n","\n"," am \n","\n"," Nar \n","\n","ay \n","\n","ana \n","\n"," San \n","\n","than \n","\n","am \n","\n"]}],"source":["for i in tokenizer.encode('I am Narayana Santhanam'):\n","    print(tokenizer.decode([i]),'\\n')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3IF_a8Ah6GTa"},"outputs":[],"source":["def get_attention_heads(model, num_layers, hidden_dim, num_heads, head_size):\n","  qkvs = []\n","  for j in range(num_layers):\n","    qkv = model.get_parameter(f\"transformer.h.{j}.attn.c_attn.weight\").detach().T\n","    ln_weight_1 = model.get_parameter(f\"transformer.h.{j}.ln_1.weight\").detach()\n","\n","    qkv = qkv - torch.mean(qkv, dim=0)\n","    qkv = torch.einsum(\"oi,i -> oi\", qkv, ln_weight_1)\n","    qkvs.append(qkv.T)\n","\n","  W_Q, W_K, W_V = torch.cat(qkvs).chunk(3, dim=-1)\n","  W_O = torch.cat([model.get_parameter(f\"transformer.h.{j}.attn.c_proj.weight\") for j in range(num_layers)]).detach()\n","  W_V_heads = W_V.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n","  W_O_heads = W_O.reshape(num_layers, num_heads, head_size, hidden_dim)\n","  W_Q_heads = W_Q.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n","  W_K_heads = W_K.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n","  return W_Q_heads, W_K_heads, W_V_heads, W_O_heads\n","\n","K,V = get_mlp_weights(model, num_layers = num_layers, hidden_dim = hidden_dim)\n","W_Q_heads, W_K_heads, W_V_heads, W_O_heads = get_attention_heads(model,\n","                                                                 num_layers=num_layers,\n","                                                                 hidden_dim=hidden_dim,\n","                                                                 num_heads=num_heads,\n","                                                                 head_size = head_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJJEGc9W6GTa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760955025244,"user_tz":600,"elapsed":31,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"707c1d05-6a7d-4994-b4df-2b49a16f2db4"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([24, 16, 1024, 64])\n","torch.Size([24, 16, 64, 1024])\n"]}],"source":["print(W_Q_heads.shape)\n","print(W_O_heads.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elRQM7Qv6GTa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768515538345,"user_tz":600,"elapsed":890,"user":{"displayName":"Narayana Santhanam","userId":"01108569549208714111"}},"outputId":"97dd00d6-df1b-4f0f-c80c-ba1ccbbd8301"},"outputs":[{"output_type":"stream","name":"stdout","text":[" the \t- \t, \t and \t a \t\n","\n","inventoryQuantity \tÃÂÃÂ \tÃÂÃÂÃÂÃÂ \trawdownload \t� \t\n","===========================================\n","\n"," hear \t listeners \t hears \t Hear \tInterstitial \t\n","\n"," write \t writing \t writes \t written \t wrote \t\n","===========================================\n","\n"," record \t Record \trecord \tRecord \t Records \t\n","\n"," news \t television \tNews \t TV \t News \t\n","===========================================\n","\n"," recording \t recordings \tYouTube \t Recording \t recorded \t\n","\n"," read \tFontSize \t Readers \t Image \t sender \t\n","===========================================\n","\n","Journal \tjournal \t print \t newspaper \t Newspaper \t\n","\n"," watch \t watched \t watching \tleased \twatch \t\n","===========================================\n","\n"]}],"source":["layer=22\n","head = 10\n","top = 5\n","VO = W_V_heads[layer, head] @ W_O_heads[layer, head]\n","U, S, Vt = torch.linalg.svd(VO)\n","values, indices = torch.topk(Vt @emb, k=top)\n","valuesm, indicesm = torch.topk(-Vt @ emb, k = top)\n","for i in range(top):\n","    for j in range(top):\n","        print(tokenizer.decode(indices[i,j]),'\\t',end=\"\")\n","    print('\\n')\n","    for j in range(top):\n","        print(tokenizer.decode(indicesm[i,j]),'\\t',end=\"\")\n","\n","    print('\\n===========================================\\n')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}